{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab9bfcd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "979bba894c024e789f3f7f85e706e40b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:  95%|#########4| 472M/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9672d0bcf0304cd4a8ed2514d60b68d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/545 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d619bee6f504ef6a987e3c48c397043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c210b7faeb2e4dbb950836c0c96e21f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8b46c5b90b411885567a5368890295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01f3b34311444a58a897b09a4dbe163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results.txt 파일로 저장되었습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Documents\\GitHub\\KOTE\\.venv\\lib\\site-packages\\transformers\\pipelines\\text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "\n",
    "model_name = \"searle-j/kote_for_easygoing_people\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "pipe = TextClassificationPipeline(model=model,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  device=-1,\n",
    "                                  return_all_scores=True,\n",
    "                                  function_to_apply='sigmoid')\n",
    "\n",
    "sentences = [\n",
    "    \"아침에 일어나긴 했는데, 몸이 좀 무거워서 한참을 가만히 있었어요.\",\n",
    "    \"해야 할 건 했죠. 밥도 먹고 설거지도 했는데, 예전처럼 손이 잘 안 가더라고요.\",\n",
    "    \"날씨는 괜찮던데, 그냥 집에 있는 게 더 편해서요.\",\n",
    "    \"네, 괜히 나갔다가 피곤해질까 봐요. 집에 있으면 조용하잖아요.\",\n",
    "    \"괜찮다고는 하는데, 사실 하루가 그냥 흘러가는 느낌이에요.\"\n",
    "]\n",
    "\n",
    "with open('results.txt', 'w', encoding='utf-8') as f:\n",
    "    for i, sentence in enumerate(sentences, 1):\n",
    "        f.write(f\"\\n[{i}] 입력 문장: {sentence}\\n\")\n",
    "        f.write(\"=\" * 70 + \"\\n\")\n",
    "        results = pipe(sentence)[0]\n",
    "        for output in results:\n",
    "            if output[\"score\"] > 0.4:\n",
    "                f.write(f\"  - {output['label']}: {output['score']:.4f}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "    \n",
    "    f.write(\"완료!\\n\")\n",
    "\n",
    "print(\"results.txt 파일로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4a8b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_name = \"searle-j/kote_for_easygoing_people\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "pipe = TextClassificationPipeline(model=model,\n",
    "                                  tokenizer=tokenizer,\n",
    "                                  device=0,\n",
    "                                  return_all_scores=True,\n",
    "                                  function_to_apply='sigmoid')\n",
    "\n",
    "# 감정 분류 매핑\n",
    "emotion_mapping = {\n",
    "    # 긍정 (15개)\n",
    "    '환영/호의': '긍정',\n",
    "    '감동/감탄': '긍정',\n",
    "    '고마움': '긍정',\n",
    "    '존경': '긍정',\n",
    "    '기대감': '긍정',\n",
    "    '뿌듯함': '긍정',\n",
    "    '편안/쾌적': '긍정',\n",
    "    '신기함/관심': '긍정',\n",
    "    '아껴주는': '긍정',\n",
    "    '흐뭇함(귀여움/예쁨)': '긍정',\n",
    "    '행복': '긍정',\n",
    "    '안심/신뢰': '긍정',\n",
    "    '깨달음': '긍정',\n",
    "    '즐거움/신남': '긍정',\n",
    "    '기쁨': '긍정',\n",
    "    \n",
    "    # 중립 (1개)\n",
    "    '없음': '중립',\n",
    "    \n",
    "    # 부정 (20개)\n",
    "    '불평/불만': '부정',\n",
    "    '지긋지긋': '부정',\n",
    "    '화남/분노': '부정',\n",
    "    '의심/불신': '부정',\n",
    "    '부끄러움': '부정',\n",
    "    '공포/무서움': '부정',\n",
    "    '절망': '부정',\n",
    "    '한심함': '부정',\n",
    "    '역겨움/징그러움': '부정',\n",
    "    '짜증': '부정',\n",
    "    '어이없음': '부정',\n",
    "    '패배/자기혐오': '부정',\n",
    "    '증오/혐오': '부정',\n",
    "    '당황/난처': '부정',\n",
    "    '경악': '부정',\n",
    "    '놀람': '부정',\n",
    "    '불안/걱정': '부정',\n",
    "    '우쭐댐/무시함': '부정',\n",
    "    '비장함': '부정',\n",
    "    \n",
    "    # 활력 저하 (8개)\n",
    "    '슬픔': '활력 저하',\n",
    "    '안타까움/실망': '활력 저하',\n",
    "    '서러움': '활력 저하',\n",
    "    '힘듦/지침': '활력 저하',\n",
    "    '재미없음': '활력 저하',\n",
    "    '부담/안_내킴': '활력 저하',\n",
    "    '불쌍함/연민': '활력 저하',\n",
    "    '귀찮음': '활력 저하',\n",
    "    '죄책감': '부정',\n",
    "}\n",
    "\n",
    "# 각 분류별 감정 개수\n",
    "category_counts = {\n",
    "    '긍정': 15,\n",
    "    '중립': 1,\n",
    "    '부정': 20,\n",
    "    '활력 저하': 8,\n",
    "}\n",
    "\n",
    "def process_file(file_path, file_type):\n",
    "    \"\"\"파일을 읽고 감정 분석 수행\"\"\"\n",
    "    df = pd.read_csv(file_path, sep='\\t', header=None, names=['id', 'text', 'labels'])\n",
    "    results = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"{file_type} 분석 진행 중\"):\n",
    "        text = row['text']\n",
    "        outputs = pipe(text)[0]\n",
    "        \n",
    "        # 감정 분류별 스코어 합계\n",
    "        emotion_scores = {'긍정': 0, '중립': 0, '활력 저하': 0, '부정': 0}\n",
    "        \n",
    "        for output in outputs:\n",
    "            if output[\"score\"] > 0:\n",
    "                label = output['label']\n",
    "                score = output['score']\n",
    "                \n",
    "                # 라벨을 분류로 매핑\n",
    "                if label in emotion_mapping:\n",
    "                    category = emotion_mapping[label]\n",
    "                    emotion_scores[category] += score\n",
    "        \n",
    "        # 각 분류별 감정 개수로 나누기\n",
    "        positive = emotion_scores['긍정'] / category_counts['긍정']\n",
    "        neutral = emotion_scores['중립'] / category_counts['중립']\n",
    "        vitality = emotion_scores['활력 저하'] / category_counts['활력 저하']\n",
    "        negative = emotion_scores['부정'] / category_counts['부정']\n",
    "        \n",
    "        result = {\n",
    "            '긍정': round(positive, 4),\n",
    "            '중립': round(neutral, 4),\n",
    "            '활력 저하': round(vitality, 4),\n",
    "            '부정': round(negative, 4),\n",
    "            'Y': round(positive * 1 + neutral * 0 + vitality * 1.5 + negative * 2, 4),\n",
    "        }\n",
    "        results.append(result)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 3개 파일 처리\n",
    "train_df = process_file('train.tsv', 'train')\n",
    "val_df = process_file('val.tsv', 'val')\n",
    "test_df = process_file('test.tsv', 'test')\n",
    "\n",
    "# 모든 데이터 합치기\n",
    "final_df = pd.concat([train_df, val_df, test_df], ignore_index=True)\n",
    "\n",
    "# 출력\n",
    "print(final_df)\n",
    "print(f\"\\n총 {len(final_df)}개 행 처리 완료\")\n",
    "\n",
    "# CSV로 저장\n",
    "final_df.to_csv('emotion_classification_final.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"결과가 'emotion_classification_final.csv'로 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49aba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 저장된 파일 읽기\n",
    "final_df = pd.read_csv('emotion_classification_final.csv', encoding='utf-8-sig')\n",
    "\n",
    "# 필요한 컬럼만 선택\n",
    "result_df = final_df[['긍정', '중립', '활력 저하', '부정', 'Y']]\n",
    "\n",
    "# 출력\n",
    "print(result_df)\n",
    "\n",
    "# CSV로 저장\n",
    "result_df.to_csv('final_cleaned.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"결과가 'emotion_classification_final_cleaned.csv'로 저장되었습니다.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
